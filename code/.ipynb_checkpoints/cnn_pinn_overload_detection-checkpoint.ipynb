{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "930549a6ebc6d3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.146851Z",
     "start_time": "2024-06-20T17:45:00.140718Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Layer, Multiply\n",
    "from tensorflow.keras.layers import Add, Dropout, BatchNormalization, Activation, LeakyReLU\n",
    "from tensorflow.keras.layers import AveragePooling2D, Reshape, Lambda, Concatenate, MultiHeadAttention, Embedding\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad, RMSprop\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow.keras.initializers import HeUniform, HeNormal, GlorotUniform\n",
    "import pandas as pd\n",
    "import gc\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "import telegram\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "86b0e75fe93d0e1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.230104Z",
     "start_time": "2024-06-20T17:45:00.226689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos disponibles: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5d6e3ae2d9f12dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:21:50.953032Z",
     "start_time": "2024-06-20T18:21:50.947562Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.load('data/matrices.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3076adf3d6eb0250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:21:51.472878Z",
     "start_time": "2024-06-20T18:21:51.113708Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data['matriz_a']\n",
    "y = data['matriz_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0511eca0-0be6-426d-a636-099132a5e7bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:22:01.752464Z",
     "start_time": "2024-06-20T18:22:01.747445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49278, 30, 8)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "12bae90e-d82b-4cbc-a1c8-d64158da8d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.652880Z",
     "start_time": "2024-06-20T17:45:00.650247Z"
    }
   },
   "outputs": [],
   "source": [
    "#, random_state=369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "65ef9a418fa4d8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.706495Z",
     "start_time": "2024-06-20T17:45:00.655245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dividir los datos inicialmente\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.15, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Revolver los conjuntos\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2ec2dbe8-45d5-4e83-92cd-338bd94917a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.712149Z",
     "start_time": "2024-06-20T17:45:00.707879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([38192,  3694]))\n",
      "(array([0., 1.]), array([3359,  337]))\n",
      "(array([0., 1.]), array([3366,  330]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_val, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7bda955ddbd7bb1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.773947Z",
     "start_time": "2024-06-20T17:45:00.713547Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3b7b756f-9f3a-4cb7-a01d-841f1ce4edcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.784141Z",
     "start_time": "2024-06-20T17:45:00.775235Z"
    }
   },
   "outputs": [],
   "source": [
    "k1 = [tf.Variable(initial_value=1.0, dtype=tf.float32, trainable=True, name=f\"k1_{i}\") for i in range(12)]\n",
    "k2 = [tf.Variable(initial_value=1.0, dtype=tf.float32, trainable=True, name=f\"k2_{i}\") for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ff714e71-cde1-41a9-9c32-e8716d9fa016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.791652Z",
     "start_time": "2024-06-20T17:45:00.785498Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + tf.exp(-z))\n",
    "\n",
    "\n",
    "def adjust_zeros(value):\n",
    "    return 1 / (tf.abs(value) + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "def normalize(x, y):\n",
    "    max_value = tf.maximum(tf.abs(x), tf.abs(y))\n",
    "    return x / (max_value + tf.keras.backend.epsilon()), y / (max_value + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "def exponential_regularizer(alpha, beta, i):\n",
    "    a_norm, b_norm = normalize(alpha, beta)\n",
    "    factor_a = adjust_zeros(a_norm)\n",
    "    factor_b = adjust_zeros(b_norm)\n",
    "    #penalization_condition = sigmoid(factor_a * a_norm) * sigmoid(-factor_b * b_norm)\n",
    "    penalization_condition = sigmoid(k1[i]*factor_a * a_norm) * sigmoid(k2[i]*-factor_b * b_norm)\n",
    "    penalization_condition = tf.round(penalization_condition)\n",
    "    #angle_difference = 1 - (2 / tf.constant(np.pi, dtype=tf.float32)) * tf.atan(tf.abs(a_norm - b_norm))\n",
    "    penalization_value = penalization_condition #* angle_difference\n",
    "    penalization_value = tf.where(penalization_value > 0, 1.0, 0.0)\n",
    "    \n",
    "    # tf.print(tf.shape(alpha))\n",
    "    # tf.print(tf.shape(beta))\n",
    "    # tf.print(tf.shape(penalization_value))\n",
    "    return penalization_value\n",
    "\n",
    "\n",
    "class PhysicRules(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PhysicRules, self).__init__()\n",
    "\n",
    "    def call(self, alpha, beta, y_pred):\n",
    "        regularizer_terms = [exponential_regularizer(alpha[i], beta[i], i) for i in range(len(alpha))]\n",
    "        reg_max = tf.reduce_max(tf.stack(regularizer_terms, axis=0), axis=0)\n",
    "        reg_max = tf.expand_dims(reg_max, axis=-1)  # Expandir dims para hacer compatible con y_pred\n",
    "        y_pred = tf.where(y_pred>=0.5,1.0,0.0)\n",
    "        loss_ = reg_max * y_pred\n",
    "        # tf.print(\"penn: \",reg_max[:10])\n",
    "        # tf.print(\"pred: \",y_pred[:10])\n",
    "        # tf.print(\"loss: \",loss_[:10])\n",
    "        return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b87e6c3a-ba17-411a-98fe-dd035c64d070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.796925Z",
     "start_time": "2024-06-20T17:45:00.793225Z"
    }
   },
   "outputs": [],
   "source": [
    "physic_rules = PhysicRules()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18b35a-d887-4227-9c06-9cbd49c1e7b1",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "73c9c30e-d769-42ce-8d6c-dc3554d2fc3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.804408Z",
     "start_time": "2024-06-20T17:45:00.800678Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_slope(inputs):    # inputs: Tensor de forma (batch_size, timesteps, features)\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "    timesteps = tf.shape(inputs)[1]\n",
    "    diffs = inputs[:, 1:, :] - inputs[:, :-1, :]  # Calcular las diferencias entre pasos temporales\n",
    "    time_intervals = tf.range(1, timesteps,\n",
    "                              dtype=tf.float32)  # Crear un tensor de intervalos de tiempo, de forma (timesteps-1)\n",
    "    time_intervals = tf.reshape(time_intervals,\n",
    "                                (1, -1, 1))  # Expandir el rango de tiempo a la forma (1, timesteps-1, 1) para la división\n",
    "    slopes = diffs / time_intervals  # Calcular las pendientes dividiendo las diferencias entre los intervalos de tiempo\n",
    "    mean_slopes = tf.reduce_mean(slopes,\n",
    "                                 axis=1)  # Promediar las pendientes a lo largo del tiempo para cada característica y cada muestra en el batch\n",
    "    return mean_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ca90e80f-d9ba-4c16-af11-9fe0a3e6a2ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.813063Z",
     "start_time": "2024-06-20T17:45:00.806096Z"
    }
   },
   "outputs": [],
   "source": [
    "class SAGLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"SAGLoss\", lambda_factor=1):\n",
    "        super(SAGLoss, self).__init__(name=name)\n",
    "        self.bce = BinaryCrossentropy()\n",
    "        self.calculate_slope = calculate_slope\n",
    "        self.lambda_factor = lambda_factor\n",
    "\n",
    "    def getGradients(self, inputs):\n",
    "        gradients = self.calculate_slope(inputs)\n",
    "        alphas = [\n",
    "            gradients[:, 4],\n",
    "            gradients[:, 6],\n",
    "            gradients[:, 0],\n",
    "            gradients[:, 3],\n",
    "            gradients[:, 0],\n",
    "            gradients[:, 1],\n",
    "            gradients[:, 4],\n",
    "            gradients[:, 2]\n",
    "        ]\n",
    "        betas = [\n",
    "            gradients[:, 3],\n",
    "            gradients[:, 3],\n",
    "            gradients[:, 1],\n",
    "            gradients[:, 7],\n",
    "            gradients[:, 2],\n",
    "            gradients[:, 2],\n",
    "            gradients[:, 7],\n",
    "            gradients[:, 4]\n",
    "        ]\n",
    "        rules = [\n",
    "            [1,1], #up & down (default relation) 1\n",
    "            [1,1],  #up & down 2\n",
    "            [-1,-1], #down & up 3\n",
    "            [-1,-1], #down & up 4\n",
    "            [-1,1], #down & down 5\n",
    "            [1,1], #up & down 6\n",
    "            [1,-1], #up & up 7\n",
    "            [1,-1] #up & up 8\n",
    "        ]\n",
    "        for i in range(len(rules)):\n",
    "            alphas[i] *= rules[i][0]\n",
    "            betas[i] *= rules[i][1]\n",
    "            \n",
    "        return alphas, betas\n",
    "\n",
    "    def getPhysicsLoss(self, inputs, y_pred):\n",
    "        alphas, betas = self.getGradients(inputs)\n",
    "        penalized_max_loss_terms = physic_rules(alphas, betas, y_pred)\n",
    "        penalized_max_loss_terms = tf.reduce_mean(penalized_max_loss_terms)\n",
    "        return penalized_max_loss_terms\n",
    "    \n",
    "    def getAllLosses(self):\n",
    "        return self.total_loss, self.focal_loss, self.physic_loss\n",
    "\n",
    "    def getTotalLoss(self, inputs, y_true, y_pred):\n",
    "        focal_loss = self.bce(y_true, y_pred)\n",
    "        physic_loss = self.getPhysicsLoss(inputs, y_pred)\n",
    "        total_loss = focal_loss + self.lambda_factor * physic_loss\n",
    "        self.total_loss = total_loss\n",
    "        self.focal_loss = focal_loss\n",
    "        self.physic_loss = physic_loss\n",
    "        return total_loss\n",
    "\n",
    "    def call(self, actual_data, y_pred):\n",
    "        inputs, y_true = actual_data\n",
    "        total_loss = self.getTotalLoss(inputs, y_true, y_pred)\n",
    "        return total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "773450894701a823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.819826Z",
     "start_time": "2024-06-20T17:45:00.814498Z"
    }
   },
   "outputs": [],
   "source": [
    "class CalculateGramMatrix(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        acceptable_kwargs = {k: v for k, v in kwargs.items() if\n",
    "                             k in ['name', 'trainable', 'dtype', 'dynamic', 'input_shape']}\n",
    "        super(CalculateGramMatrix, self).__init__(**acceptable_kwargs)\n",
    "        #inn physics layer: [4,3], [6,4], [6,3], [3,5]\n",
    "        self.pairs_n = kwargs.get('pairs_n',\n",
    "                                  [[4, 3], [6, 4], [6, 3], [3, 5], [0, 1], [3, 7], [5, 7], [0, 2], [1, 2], [4, 7],\n",
    "                                   [2, 4]])\n",
    "        #self.pairs_n = kwargs.get('pairs_n', [[0,1],[3,7],[5,7],[0,2],[1,2],[4,6],[3,6],[3,4],[4,7],[2,4]])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        angles = tf.math.acos(inputs)\n",
    "\n",
    "        matrix = []\n",
    "        for i, j in self.pairs_n:\n",
    "            angles_j1 = angles[:, :, i]  # Ángulos de la primera variable (j1)\n",
    "            angles_j2 = angles[:, :, j]  # Ángulos de la segunda variable (j2)\n",
    "\n",
    "            # Expande las dimensiones para realizar una resta entre cada par de ángulos\n",
    "            angles_j1_expanded = tf.expand_dims(angles_j1, axis=2)\n",
    "            angles_j2_expanded = tf.expand_dims(angles_j2, axis=1)\n",
    "\n",
    "            # Calcula la matriz de diferencias angulares (30x30)\n",
    "            angular_difference_matrix = angles_j1_expanded - angles_j2_expanded\n",
    "            matrix.append(angular_difference_matrix)\n",
    "\n",
    "        # Apila todas las matrices calculadas a lo largo de un nuevo eje\n",
    "        m = tf.stack(matrix, axis=-1)\n",
    "\n",
    "        return m\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'pairs_n': self.pairs_n})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5e66467ed8a39f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.826513Z",
     "start_time": "2024-06-20T17:45:00.821116Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTemporalFilter(Layer):\n",
    "    def __init__(self, filter_size, **kwargs):\n",
    "        super(CustomTemporalFilter, self).__init__(**kwargs)\n",
    "        self.filter_size = filter_size\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomTemporalFilter, self).get_config()\n",
    "        config.update({\n",
    "            \"filter_size\": self.filter_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Generar un filtro de atención que decrece desde la esquina inferior derecha \n",
    "        # hacia la esquina superior izquierda.\n",
    "\n",
    "        # Crear una matriz 2D donde cada elemento es el valor de su índice normalizado.\n",
    "        # Esto crea un gradiente que decrece hacia la esquina superior izquierda.\n",
    "        x = tf.linspace(1.0, 0.0, self.filter_size)\n",
    "        y = tf.linspace(1.0, 0.0, self.filter_size)\n",
    "        X, Y = tf.meshgrid(x, y)\n",
    "        self.attention_filter = 1.0 - ((X + Y) / 2.0)  # Normaliza para que los valores vayan de 0 a 1\n",
    "        self.attention_filter = tf.reshape(self.attention_filter, (1, self.filter_size, self.filter_size, 1))\n",
    "        self.attention_filter = tf.cast(self.attention_filter, dtype='float32')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ajusta el filtro de atención para que coincida con el tamaño del batch y el número de canales de las entradas.\n",
    "        attention_filter_broadcasted = tf.tile(self.attention_filter, [tf.shape(inputs)[0], 1, 1, tf.shape(inputs)[-1]])\n",
    "\n",
    "        # Aplica el filtro de atención a las entradas.\n",
    "        return inputs * attention_filter_broadcasted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "88e3da85-03a0-462f-92fb-0e6475697720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.831921Z",
     "start_time": "2024-06-20T17:45:00.827949Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinMaxScalingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, min_value=-1, max_value=1, **kwargs):\n",
    "        super(MinMaxScalingLayer, self).__init__(**kwargs)\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs)\n",
    "        max_val = tf.reduce_max(inputs)\n",
    "        scaled = (inputs - min_val) / (max_val - min_val)  # Escalar entre 0 y 1\n",
    "        return scaled * (self.max_value - self.min_value) + self.min_value  # Escalar entre min_value y max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "50aa5dd6361d7fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.838637Z",
     "start_time": "2024-06-20T17:45:00.833321Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(num_conv_layers, num_dense_layers, num_neurons, dropout_rate, conv_filters):\n",
    "    input_layer = Input(shape=(30, 8), name=\"Input\")\n",
    "    m = CalculateGramMatrix(name=\"Gram_converter\")(input_layer)\n",
    "    m = CustomTemporalFilter(filter_size=30, name=\"Temporal_filter\")(m)\n",
    "\n",
    "    # Add convolutional layers dynamically\n",
    "    for i in range(num_conv_layers):\n",
    "        print(f'conv_filters: {conv_filters * (2 ** i)}')\n",
    "        m = Conv2D(filters=conv_filters * (2 ** i), kernel_size=(3, 3), use_bias=False, kernel_initializer='he_normal')(\n",
    "            m)\n",
    "        m = BatchNormalization()(m)\n",
    "        m = LeakyReLU(alpha=0.01)(m)\n",
    "        m = AveragePooling2D(pool_size=(2, 2))(m)\n",
    "\n",
    "    c = Flatten(name=\"Flattened_after_full\")(m)\n",
    "\n",
    "    # Add dense layers dynamically\n",
    "    for j in range(num_dense_layers):\n",
    "        print(f'num_neurons: {num_neurons // (2 ** j)}')\n",
    "        c = Dense(num_neurons // (2 ** j), activation='relu', kernel_initializer='he_normal')(c)\n",
    "        c = Dropout(dropout_rate)(c)\n",
    "        c = BatchNormalization()(c)\n",
    "    output_layer = Dense(1, activation='sigmoid', name=\"Output\")(c)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c6160afd6d36cae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.843257Z",
     "start_time": "2024-06-20T17:45:00.840107Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_model():\n",
    "    tf.keras.backend.clear_session()\n",
    "    try:\n",
    "        del model\n",
    "        del optimizer\n",
    "    except:\n",
    "        None\n",
    "    for i in range(15):\n",
    "        gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "df8c93bf695b599f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.849098Z",
     "start_time": "2024-06-20T17:45:00.844693Z"
    }
   },
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "446b6348-62fc-4934-8876-3f5f6e07a293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.862062Z",
     "start_time": "2024-06-20T17:45:00.850538Z"
    }
   },
   "outputs": [],
   "source": [
    "pinn_loss = SAGLoss(\"SAGLoss\")\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, y_true, model, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(inputs, training=True)\n",
    "        total_loss= pinn_loss((inputs, y_true), y_pred)\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1100e1e7-2481-468f-b4eb-048825e72b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.867346Z",
     "start_time": "2024-06-20T17:45:00.863935Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_conv_layers': 2,\n",
    "    'num_dense_layers': 3,\n",
    "    'num_neurons': 1024,\n",
    "    'dropout_rate': 0.3,\n",
    "    'lambda_factor': 1.0,\n",
    "    'conv_filters': 64  # Different base numbers of filters for the convolutional layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cb4e5f51-ea9a-4c6e-95a3-896887c5927a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.880725Z",
     "start_time": "2024-06-20T17:45:00.868867Z"
    }
   },
   "outputs": [],
   "source": [
    "precision_metric = Precision()\n",
    "recall_metric = Recall()\n",
    "bce = BinaryFocalCrossentropy()\n",
    "f1_metric = F1Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7e4c67d5-c4be-4751-9d02-bb0acc86b78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.892954Z",
     "start_time": "2024-06-20T17:45:00.882142Z"
    }
   },
   "outputs": [],
   "source": [
    "patience = 50\n",
    "epochs = 5000\n",
    "cont_patience = 0\n",
    "min_patience = 0\n",
    "best_model = None\n",
    "del_model()\n",
    "lambda_factor = params['lambda_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2026f9b6-f585-478c-8609-c7e917ec007f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:00.899824Z",
     "start_time": "2024-06-20T17:45:00.896472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_filters: 64, dropout_rate: 0.3, lambda_factor: 1.0, num_conv_layers: 2, num_dense_layers: 3, num_neurons: 1024\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'conv_filters: {params[\"conv_filters\"]}, dropout_rate: {params[\"dropout_rate\"]}, lambda_factor: {params[\"lambda_factor\"]}, num_conv_layers: {params[\"num_conv_layers\"]}, num_dense_layers: {params[\"num_dense_layers\"]}, num_neurons: {params[\"num_neurons\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a215f847-7960-48b0-aa7b-1d3741ba5fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:01.106021Z",
     "start_time": "2024-06-20T17:45:00.901256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_filters: 64\n",
      "conv_filters: 128\n",
      "num_neurons: 1024\n",
      "num_neurons: 512\n",
      "num_neurons: 256\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    num_conv_layers=params['num_conv_layers'],\n",
    "    num_dense_layers=params['num_dense_layers'],\n",
    "    num_neurons=params['num_neurons'],\n",
    "    dropout_rate=params['dropout_rate'],\n",
    "    conv_filters=params['conv_filters']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1ff293df-06e5-4151-986b-a4a8e8f4db43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:01.110867Z",
     "start_time": "2024-06-20T17:45:01.108154Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "673f2b0c-5223-4128-b16a-c431c91a31da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:01.137504Z",
     "start_time": "2024-06-20T17:45:01.112186Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "optimizer.build(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3b042c7e-270d-477c-aa2b-ebd250898fc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:01.141905Z",
     "start_time": "2024-06-20T17:45:01.139266Z"
    }
   },
   "outputs": [],
   "source": [
    "# from livelossplot import PlotLosses, MainLogger\n",
    "# from livelossplot.outputs import BaseOutput\n",
    "# groups = {'f1-score': ['f1_score', 'min_patience']}\n",
    "# plotlosses = PlotLosses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "329f382ad0312392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T17:45:01.146334Z",
     "start_time": "2024-06-20T17:45:01.143599Z"
    }
   },
   "outputs": [],
   "source": [
    "cont_patience=0\n",
    "patience = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c18e95b8-a43c-464b-ac14-90462e115914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:51.675609Z",
     "start_time": "2024-06-20T17:45:01.152403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1260, ULTIMO   <total_loss: 0.16821610927581787> <bce_loss: 0.08244771510362625> <physics_loss: 0.08576840162277222> 0.95->0.9402984380722046 (201)    "
     ]
    }
   ],
   "source": [
    "precision = 10e-4  #decimal precision for replace better model\n",
    "for epoch in range(epochs):\n",
    "    for step in range(0, len(X_train), 2048):\n",
    "        X_batch = X_train[step:step + 2048]\n",
    "        y_batch = y_train[step:step + 2048]\n",
    "        loss_value = train_step(X_batch, y_batch, model, optimizer)\n",
    "\n",
    "    y_pred_val = model(X_val)\n",
    "    total_loss= pinn_loss((X_val, y_val), y_pred_val)\n",
    "    _,bce_loss,physics_loss=pinn_loss.getAllLosses()\n",
    "\n",
    "    f1_metric.update_state(y_val, y_pred_val)\n",
    "    f1_score = f1_metric.result().numpy()\n",
    "    f1_metric.reset_states()\n",
    "    #logs = {'focal_l': focal_loss, 'physics_l': physics_loss, 'val_l': val_loss, 'f1_score': f1_score,\n",
    "    #        'min_patience': min_patience}\n",
    "    #plotlosses.update(logs)\n",
    "    #plotlosses.send()\n",
    "    if (tf.abs(f1_score - min_patience)<(precision))or(f1_score>min_patience):\n",
    "    #if f1_score > min_patience:\n",
    "        sys.stdout.write(\n",
    "            f\"\\rEpoch {epoch}, SUPERADO <total_loss: {total_loss}> <bce_loss: {bce_loss}> <physics_loss: {physics_loss}> {min_patience}->{f1_score} ({cont_patience + 1})     \")\n",
    "        cont_patience = 0\n",
    "        sys.stdout.flush()\n",
    "        best_model = model\n",
    "        min_patience = tf.floor(f1_score * 100)/100\n",
    "        increase=True\n",
    "\n",
    "    else:\n",
    "        cont_patience += 1\n",
    "        sys.stdout.write(\n",
    "            f\"\\rEpoch {epoch}, ULTIMO   <total_loss: {total_loss}> <bce_loss: {bce_loss}> <physics_loss: {physics_loss}> {min_patience}->{f1_score} ({cont_patience})    \")\n",
    "        sys.stdout.flush()\n",
    "        if cont_patience > patience:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9d8ac109b0dc150e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.163962Z",
     "start_time": "2024-06-20T18:09:51.677065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f29bc8cf-c184-48de-9a81-c9181b88622f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.168565Z",
     "start_time": "2024-06-20T18:09:52.165497Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "40b94576-1202-41d0-a890-242a4120dddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.183226Z",
     "start_time": "2024-06-20T18:09:52.170749Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1e63572b49ec4e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.188538Z",
     "start_time": "2024-06-20T18:09:52.184555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3352,   14,   27,  303])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "816c08d1-64e6-46c8-ac2e-08f3671a03e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.193647Z",
     "start_time": "2024-06-20T18:09:52.190033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3352,   14],\n",
       "       [  27,  303]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4ced8a1b-648c-41cd-945f-642bcd4da557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.197713Z",
     "start_time": "2024-06-20T18:09:52.194860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate Sensitivity\n",
    "def calculate_sensitivity(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "\n",
    "# Function to calculate Specificity\n",
    "def calculate_specificity(tn, fp):\n",
    "    return tn / (tn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5624c19e-66cf-43a6-ba18-554d02d7ddc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.203557Z",
     "start_time": "2024-06-20T18:09:52.198904Z"
    }
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "675eb649-1f03-451a-b5a7-01876cdc3321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.207642Z",
     "start_time": "2024-06-20T18:09:52.204913Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as f1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a0b27f63-599f-408b-9582-2560ed7c997d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.216865Z",
     "start_time": "2024-06-20T18:09:52.210664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity o Recall: 0.9181818181818182\n",
      "Specificity: 0.995840760546643\n",
      "Precision 0.9558359621451105\n",
      "F1 Score: 0.9366306027820711\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_s(y_test, y_pred)\n",
    "\n",
    "# Calculate Sensitivity\n",
    "sensitivity = calculate_sensitivity(tp, fn)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = calculate_specificity(tn, fp)\n",
    "\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "\n",
    "f1 = 2 * ((recall * precision) / (recall + precision))\n",
    "\n",
    "# Print results\n",
    "print(\"Sensitivity o Recall:\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision\", precision)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0bc816d8-b8a1-4ddb-963f-fdcd207a6e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.350041Z",
     "start_time": "2024-06-20T18:09:52.218199Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models//final_20240620_vA_pinn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5e043b36-73a3-49a9-94ce-5be535563f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.353655Z",
     "start_time": "2024-06-20T18:09:52.351471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0706f238-5a80-4d82-a30f-0764be867785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.357096Z",
     "start_time": "2024-06-20T18:09:52.354973Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fd8b9b7c4336da1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.360242Z",
     "start_time": "2024-06-20T18:09:52.358300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1a96b38f0009f3b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.363489Z",
     "start_time": "2024-06-20T18:09:52.361462Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "985c4a3cc811bc77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.366544Z",
     "start_time": "2024-06-20T18:09:52.364724Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d814a640fc6b43d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T18:09:52.369614Z",
     "start_time": "2024-06-20T18:09:52.367777Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
